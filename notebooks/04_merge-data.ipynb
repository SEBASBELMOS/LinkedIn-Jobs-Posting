{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROJECT - NOTEBOOK #4: Merge LinkedIn and USAJOBS Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setting Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\U\\FIFTH SEMESTER\\ETL\\project_etl\\notebooks\n",
      "d:\\U\\FIFTH SEMESTER\\ETL\\project_etl\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "try:\n",
    "    os.chdir(\"../../project_etl\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\"\"\n",
    "        FileNotFoundError - The directory may not exist or you might not be in the specified path.\n",
    "        If this has already worked, do not run this block again, as the current directory is already set to project_etl.\n",
    "        \"\"\")\n",
    "    \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = create_engine('postgresql://root:root@localhost:5432/linkedin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_linkedin = pd.read_sql_table('merge', schema='dimensional_model', con=engine)\n",
    "df_linkedin = pd.read_csv('data_merged/merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "usajobs_file = [f for f in os.listdir('.') if f.startswith('usajobs_data_') and f.endswith('.csv')][0]\n",
    "df_usajobs = pd.read_csv(usajobs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinkedIn Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                123849 non-null  object \n",
      " 2   company_id                  123849 non-null  int64  \n",
      " 3   views                       122160 non-null  float64\n",
      " 4   formatted_work_type         123849 non-null  object \n",
      " 5   applies                     123849 non-null  int64  \n",
      " 6   remote_allowed              123849 non-null  int64  \n",
      " 7   application_type            123849 non-null  object \n",
      " 8   formatted_experience_level  123849 non-null  object \n",
      " 9   normalized_salary           36073 non-null   float64\n",
      " 10  len_description             123842 non-null  float64\n",
      " 11  state_only                  123849 non-null  object \n",
      " 12  original_listed_month       123849 non-null  object \n",
      " 13  original_listed_year        123849 non-null  int64  \n",
      " 14  has_benefits                123849 non-null  float64\n",
      " 15  benefits_count              123849 non-null  float64\n",
      " 16  industry_category           123849 non-null  object \n",
      " 17  skills_list                 122096 non-null  object \n",
      " 18  company_size                123849 non-null  int64  \n",
      " 19  employee_count              123849 non-null  int64  \n",
      " 20  follower_count              123849 non-null  int64  \n",
      "dtypes: float64(5), int64(8), object(8)\n",
      "memory usage: 19.8+ MB\n",
      "None\n",
      "\n",
      "USAJOBS Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 886 entries, 0 to 885\n",
      "Data columns (total 29 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   PositionID          886 non-null    object \n",
      " 1   PositionTitle       886 non-null    object \n",
      " 2   PositionURI         886 non-null    object \n",
      " 3   Location            886 non-null    object \n",
      " 4   City                886 non-null    object \n",
      " 5   State               886 non-null    object \n",
      " 6   Country             886 non-null    object \n",
      " 7   Latitude            886 non-null    float64\n",
      " 8   Longitude           886 non-null    float64\n",
      " 9   Organization        886 non-null    object \n",
      " 10  Department          886 non-null    object \n",
      " 11  MinSalary           886 non-null    float64\n",
      " 12  MaxSalary           886 non-null    float64\n",
      " 13  SalaryInterval      886 non-null    object \n",
      " 14  JobCategory         886 non-null    object \n",
      " 15  JobGrade            884 non-null    object \n",
      " 16  Schedule            66 non-null     object \n",
      " 17  OfferingType        78 non-null     object \n",
      " 18  StartDate           886 non-null    object \n",
      " 19  EndDate             886 non-null    object \n",
      " 20  PublicationDate     886 non-null    object \n",
      " 21  CloseDate           886 non-null    object \n",
      " 22  TeleworkEligible    886 non-null    bool   \n",
      " 23  SecurityClearance   886 non-null    object \n",
      " 24  PromotionPotential  401 non-null    object \n",
      " 25  TravelCode          886 non-null    int64  \n",
      " 26  HiringPath          886 non-null    object \n",
      " 27  TotalOpenings       886 non-null    object \n",
      " 28  NormalisedSalary    886 non-null    float64\n",
      "dtypes: bool(1), float64(5), int64(1), object(22)\n",
      "memory usage: 194.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"LinkedIn Data Info:\")\n",
    "print(df_linkedin.info())\n",
    "print(\"\\nUSAJOBS Data Info:\")\n",
    "print(df_usajobs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values of 'state_only' in df_linkedin before processing:\n",
      "['nj' 'co' 'oh' 'ny' 'ia' 'nc' 'other' 'ca' 'ne' 'fl' 'mi' 'mo' 'tn' 'ak'\n",
      " 'ri' 'al' 'ga' 'tx' 'pa' 'ma' 'az' 'va' 'wa' 'wi' 'hi' 'sd' 'la' 'ut'\n",
      " 'in' 'mn' 'md' 'ky' 'or' 'nm' 'il' 'mt' 'ok' 'dc' 'ms' 'sc' 'ks' 'nv'\n",
      " 'ar' 'ct' 'id' 'nh' 'wy' 'me' 'nd' 'de' 'wv' 'vt']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique values of 'state_only' in df_linkedin before processing:\")\n",
    "print(df_linkedin['state_only'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values of 'state_only' in df_usajobs before processing:\n",
      "['Illinois' 'Georgia' 'Massachusetts' 'Pennsylvania' 'Hawaii' 'Nebraska'\n",
      " 'Minnesota' 'Maryland' 'California' 'Colorado' 'Virginia' 'Oklahoma'\n",
      " 'New York' 'Wisconsin' 'Alabama' 'Arkansas' 'New Mexico' 'New Jersey'\n",
      " 'Utah' 'Montana' 'Alaska' 'Wyoming' 'Washington' 'North Carolina'\n",
      " 'Florida' 'Tennessee' 'Texas' 'Nevada' 'South Dakota' 'West Virginia'\n",
      " 'Kansas' 'Louisiana' 'Vermont' 'Arizona' 'North Dakota' 'Kentucky'\n",
      " 'Delaware' 'Oregon' 'Indiana' 'Idaho' 'Maine' 'Unknown' 'Missouri'\n",
      " 'District of Columbia' 'South Carolina' 'Iowa' 'Michigan' 'Rhode Island'\n",
      " 'Puerto Rico' 'Guam' 'Connecticut' 'Ohio' 'Mississippi' 'New Hampshire'\n",
      " 'Virgin Islands']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique values of 'state_only' in df_usajobs before processing:\")\n",
    "print(df_usajobs['State'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/mshafrir/2646763/raw/states_titlecase.json'\n",
    "state_list = json.load(urlopen(url))\n",
    "abbr_map = {item['abbreviation']: item['abbreviation'] for item in state_list}\n",
    "name_map = {item['name'].lower(): item['abbreviation'] for item in state_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(loc: str) -> str:\n",
    "    if pd.isna(loc) or not isinstance(loc, str):\n",
    "        return 'OTHER'\n",
    "    for frag in reversed([f.strip() for f in loc.split(',')]):\n",
    "        code = frag.upper()\n",
    "        name = frag.lower()\n",
    "        if code in abbr_map:\n",
    "            return code\n",
    "        if name in name_map:\n",
    "            return name_map[name]\n",
    "    return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkedin['state_only'] = df_linkedin['state_only'].apply(extract_state)\n",
    "df_usajobs = df_usajobs.rename(columns={'State': 'state_only'})\n",
    "df_usajobs['state_only'] = df_usajobs['state_only'].apply(extract_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs = df_usajobs.rename(columns={\n",
    "    'NormalisedSalary': 'normalized_salary',\n",
    "    'TeleworkEligible': 'remote_allowed',\n",
    "    'JobCategory': 'industry_category',\n",
    "    'PublicationDate': 'original_listed_time'  # Temporary rename for month/year extraction\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs['original_listed_month'] = pd.to_datetime(df_usajobs['original_listed_time'], errors='coerce').dt.month_name().fillna('OTHER')\n",
    "df_usajobs['original_listed_year'] = pd.to_datetime(df_usajobs['original_listed_time'], errors='coerce').dt.year.fillna(0).astype(int)\n",
    "df_usajobs = df_usajobs.drop(columns=['original_listed_time'])  # Clean up temporary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkedin['normalized_salary'] = pd.to_numeric(df_linkedin['normalized_salary'], errors='coerce').fillna(0)\n",
    "df_usajobs['normalized_salary'] = pd.to_numeric(df_usajobs['normalized_salary'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkedin['industry_category'] = df_linkedin['industry_category'].fillna('OTHER')\n",
    "df_usajobs['industry_category'] = df_usajobs['industry_category'].fillna('OTHER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Map JobCategory to industry_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_patterns = {\n",
    "    r'\\b(manufacturing|production|fabrication)\\b': 'Manufacturing',\n",
    "    r'\\b(tech|it|information|computer|software|internet|data)\\b': 'Technology & IT',\n",
    "    r'\\b(health|medical|pharma|bio|dental|clinic|veterinary)\\b': 'Healthcare & Life Sciences',\n",
    "    r'\\b(finance|bank|insurance|investment|accounting)\\b': 'Finance & Insurance',\n",
    "    r'\\b(retail|e-commerce|fashion|apparel|luxury)\\b': 'Retail & Consumer Goods',\n",
    "    r'\\b(education|e-learning|school|training|academic)\\b': 'Education',\n",
    "    r'\\b(government|public|law|justice|military)\\b': 'Government & Public Sector',\n",
    "    r'\\b(media|entertainment|arts|sports|hospitality|travel)\\b': 'Media, Entertainment & Hospitality',\n",
    "    r'\\b(energy|oil|gas|mining|utilities|power|solar|wind)\\b': 'Energy, Mining & Utilities',\n",
    "    r'\\b(construction|real estate|architecture|engineering)\\b': 'Construction & Real Estate',\n",
    "    r'\\b(transportation|logistics|supply chain|automotive|aerospace)\\b': 'Transportation & Logistics',\n",
    "    r'\\b(food|beverage|restaurants|catering)\\b': 'Food & Beverage Services',\n",
    "    r'\\b(non-?profit|charity|community)\\b': 'Non-Profit & Social Organizations',\n",
    "    r'\\b(agriculture|farming|forestry|horticulture)\\b': 'Agriculture & Forestry',\n",
    "    r'other': 'OTHER'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_industry_category(category):\n",
    "    if pd.isna(category) or category == 'OTHER':\n",
    "        return 'OTHER'\n",
    "    category = category.lower()\n",
    "    for pattern, mapped_category in category_patterns.items():\n",
    "        if re.search(pattern, category):\n",
    "            return mapped_category\n",
    "    return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs['industry_category'] = df_usajobs['industry_category'].apply(map_industry_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Align Columns for Concatenation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [\n",
    "    'job_id', 'company_id', 'company_name', 'company_size', 'employee_count', 'follower_count',\n",
    "    'views', 'applies', 'formatted_work_type', 'remote_allowed', 'application_type',\n",
    "    'formatted_experience_level', 'normalized_salary', 'len_description', 'state_only',\n",
    "    'original_listed_month', 'original_listed_year', 'has_benefits', 'benefits_count',\n",
    "    'industry_category', 'skills_list'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in final_columns:\n",
    "    if col not in df_linkedin.columns:\n",
    "        if col in ['company_id', 'company_size', 'employee_count', 'follower_count', 'views', 'applies', 'len_description', 'has_benefits', 'benefits_count']:\n",
    "            df_linkedin[col] = 0\n",
    "        else:\n",
    "            df_linkedin[col] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs_aligned = pd.DataFrame(columns=final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'job_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'job_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_usajobs_aligned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_usajobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m df_usajobs_aligned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Not available in df_usajobs\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df_usajobs_aligned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Not directly available, could map from Organization if needed\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'job_id'"
     ]
    }
   ],
   "source": [
    "df_usajobs_aligned['job_id'] = df_usajobs['job_id']\n",
    "df_usajobs_aligned['company_id'] = 0  # Not available in df_usajobs\n",
    "df_usajobs_aligned['company_name'] = 'Unknown'  # Not directly available, could map from Organization if needed\n",
    "df_usajobs_aligned['company_size'] = 0\n",
    "df_usajobs_aligned['employee_count'] = 0\n",
    "df_usajobs_aligned['follower_count'] = 0\n",
    "df_usajobs_aligned['views'] = 0\n",
    "df_usajobs_aligned['applies'] = 0\n",
    "df_usajobs_aligned['formatted_work_type'] = 'Unknown'  # Not available, set default\n",
    "df_usajobs_aligned['remote_allowed'] = df_usajobs['remote_allowed']\n",
    "df_usajobs_aligned['application_type'] = 'Unknown'  # Not available, set default\n",
    "df_usajobs_aligned['formatted_experience_level'] = 'Unknown'  # Not available, set default\n",
    "df_usajobs_aligned['normalized_salary'] = df_usajobs['normalized_salary']\n",
    "df_usajobs_aligned['len_description'] = 0  # Not available\n",
    "df_usajobs_aligned['state_only'] = df_usajobs['state_only']\n",
    "df_usajobs_aligned['original_listed_month'] = df_usajobs['original_listed_month']\n",
    "df_usajobs_aligned['original_listed_year'] = df_usajobs['original_listed_year']\n",
    "df_usajobs_aligned['has_benefits'] = 0\n",
    "df_usajobs_aligned['benefits_count'] = 0\n",
    "df_usajobs_aligned['industry_category'] = df_usajobs['industry_category']\n",
    "df_usajobs_aligned['skills_list'] = ''  # Not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs_aligned['job_id'] = df_usajobs_aligned['job_id'].astype(str) \n",
    "df_linkedin['job_id'] = df_linkedin['job_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Concatenate the Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_27844\\2787624072.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_linkedin[final_columns], df_usajobs_aligned], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.concat([df_linkedin[final_columns], df_usajobs_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated job_ids: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_merged['job_id'].duplicated().sum()\n",
    "print(f\"Number of duplicated job_ids: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop_duplicates(subset=['job_id'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Merged Data Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  object \n",
      " 1   company_id                  123849 non-null  object \n",
      " 2   company_name                123849 non-null  object \n",
      " 3   company_size                123849 non-null  object \n",
      " 4   employee_count              123849 non-null  object \n",
      " 5   follower_count              123849 non-null  object \n",
      " 6   views                       122160 non-null  float64\n",
      " 7   applies                     123849 non-null  object \n",
      " 8   formatted_work_type         123849 non-null  object \n",
      " 9   remote_allowed              123849 non-null  object \n",
      " 10  application_type            123849 non-null  object \n",
      " 11  formatted_experience_level  123849 non-null  object \n",
      " 12  normalized_salary           123849 non-null  float64\n",
      " 13  len_description             123842 non-null  float64\n",
      " 14  state_only                  123849 non-null  object \n",
      " 15  original_listed_month       123849 non-null  object \n",
      " 16  original_listed_year        123849 non-null  object \n",
      " 17  has_benefits                123849 non-null  float64\n",
      " 18  benefits_count              123849 non-null  float64\n",
      " 19  industry_category           123849 non-null  object \n",
      " 20  skills_list                 122096 non-null  object \n",
      "dtypes: float64(5), object(16)\n",
      "memory usage: 19.8+ MB\n",
      "None\n",
      "\n",
      "=== Missing Values in Merged Data ===\n",
      "job_id                           0\n",
      "company_id                       0\n",
      "company_name                     0\n",
      "company_size                     0\n",
      "employee_count                   0\n",
      "follower_count                   0\n",
      "views                         1689\n",
      "applies                          0\n",
      "formatted_work_type              0\n",
      "remote_allowed                   0\n",
      "application_type                 0\n",
      "formatted_experience_level       0\n",
      "normalized_salary                0\n",
      "len_description                  7\n",
      "state_only                       0\n",
      "original_listed_month            0\n",
      "original_listed_year             0\n",
      "has_benefits                     0\n",
      "benefits_count                   0\n",
      "industry_category                0\n",
      "skills_list                   1753\n",
      "dtype: int64\n",
      "\n",
      "=== First 5 Rows of Merged Data ===\n",
      "     job_id company_id            company_name company_size employee_count  \\\n",
      "0    921716    2774458   corcoran sawyer smith            2            402   \n",
      "1   1829192         -1                 unknown            0              0   \n",
      "2  10998357   64896719  the national exemplar             1             15   \n",
      "3  23221523     766262  abrams fensterman, llp            2            222   \n",
      "4  35982263         -1                 unknown            0              0   \n",
      "\n",
      "  follower_count  views applies formatted_work_type remote_allowed  ...  \\\n",
      "0           2351   20.0       2           full-time              0  ...   \n",
      "1              0    1.0       0           full-time              0  ...   \n",
      "2             40    8.0       0           full-time              0  ...   \n",
      "3           2427   16.0       0           full-time              0  ...   \n",
      "4              0    3.0       0           full-time              0  ...   \n",
      "\n",
      "  formatted_experience_level normalized_salary  len_description  state_only  \\\n",
      "0                    unknown           38480.0           2526.0          NJ   \n",
      "1                    unknown           83200.0           3560.0          CO   \n",
      "2                    unknown           55000.0            462.0          OH   \n",
      "3                    unknown          157500.0           1599.0          NY   \n",
      "4                    unknown           70000.0            232.0          IA   \n",
      "\n",
      "  original_listed_month original_listed_year has_benefits  benefits_count  \\\n",
      "0                 april                 2024          0.0             0.0   \n",
      "1                 april                 2024          0.0             0.0   \n",
      "2                 april                 2024          0.0             0.0   \n",
      "3                 april                 2024          1.0             1.0   \n",
      "4                 april                 2024          0.0             0.0   \n",
      "\n",
      "            industry_category               skills_list  \n",
      "0  construction & real estate           marketing,sales  \n",
      "1                     unknown      health care provider  \n",
      "2    food & beverage services  management,manufacturing  \n",
      "3  government & public sector                     other  \n",
      "4                       other    information technology  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Merged Data Info ===\")\n",
    "print(df_merged.info())\n",
    "print(\"\\n=== Missing Values in Merged Data ===\")\n",
    "print(df_merged.isna().sum())\n",
    "print(\"\\n=== First 5 Rows of Merged Data ===\")\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Merged Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to linkedin_usajobs_merged_20250520_124705.csv\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "merged_file = f\"linkedin_usajobs_merged_{timestamp}.csv\"\n",
    "df_merged.to_csv(merged_file, index=False)\n",
    "print(f\"Merged data saved to {merged_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/linkedin')\n",
    "\n",
    "df_merged.to_sql(\n",
    "    'linkedin_usajobs_merged',\n",
    "    con=engine,\n",
    "    schema='dimensional_model', #TODO maybe create a new schema for this \n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "print(\"Merged data saved to dimensional_model.linkedin_usajobs_merged\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
