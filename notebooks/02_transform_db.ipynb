{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/linkedin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('postings', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_description'] = df['description'].str.len()\n",
    "\n",
    "to_drop = [\n",
    "    'description','job_posting_url','application_url','posting_domain',\n",
    "    'compensation_type','fips','work_type','sponsored','listed_time',\n",
    "    'expiry','closed_time','skills_desc','title'\n",
    "]\n",
    "df = df.drop(columns=to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "url = 'https://gist.githubusercontent.com/mshafrir/2646763/raw/states_titlecase.json'\n",
    "state_list = json.load(urlopen(url))\n",
    "abbr_map = {item['abbreviation']: item['abbreviation'] for item in state_list}\n",
    "name_map = {item['name'].lower(): item['abbreviation'] for item in state_list}\n",
    "\n",
    "def extract_state(loc: str) -> str:\n",
    "    if pd.isna(loc) or not isinstance(loc, str):\n",
    "        return 'UNKNOWN'\n",
    "    for frag in reversed([f.strip() for f in loc.split(',')]):\n",
    "        code = frag.upper()\n",
    "        name = frag.lower()\n",
    "        if code in abbr_map:\n",
    "            return code\n",
    "        if name in name_map:\n",
    "            return name_map[name]\n",
    "    return 'OTHER'\n",
    "\n",
    "df['state_only'] = df['location'].apply(extract_state)\n",
    "df = df.drop(columns=['location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['applies']                  = df['applies'].fillna(0).astype(int)\n",
    "df['company_name']             = df['company_name'].fillna('Unknown')\n",
    "df['formatted_experience_level']= df['formatted_experience_level'].fillna('Unknown')\n",
    "df['remote_allowed']           = df['remote_allowed'].fillna(0).astype('Int8')\n",
    "df['company_id']               = df['company_id'].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.to_datetime(df['original_listed_time'], unit='ms')\n",
    "df['original_listed_month'] = dt.dt.month_name()\n",
    "df['original_listed_year']  = dt.dt.year\n",
    "\n",
    "df = df.drop(columns=['original_listed_time','zip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates = {\n",
    "    'USD': 1.0, 'EUR': 1.10, 'CAD': 0.75,\n",
    "    'BBD': 0.50,'AUD': 0.65,'GBP': 1.25,\n",
    "}\n",
    "for col in ['min_salary','med_salary','max_salary']:\n",
    "    rate = df['currency'].map(exchange_rates).fillna(1.0)\n",
    "    df[col] = df[col] * rate\n",
    "df = df.drop(columns=['currency'])\n",
    "\n",
    "factor = {'HOURLY':2080,'MONTHLY':12,'WEEKLY':52,'BIWEEKLY':26,'YEARLY':1}\n",
    "\n",
    "df[['min_salary','med_salary','max_salary']] = df[\n",
    "    ['min_salary','med_salary','max_salary']\n",
    "].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df['min_salary_annual'] = df['min_salary'] * df['pay_period'].map(factor)\n",
    "df['max_salary_annual'] = df['max_salary'] * df['pay_period'].map(factor)\n",
    "df['med_salary_annual'] = df['med_salary'] * df['pay_period'].map(factor)\n",
    "\n",
    "df['normalized_salary'] = df[\n",
    "    ['min_salary_annual','med_salary_annual','max_salary_annual']\n",
    "].mean(axis=1)\n",
    "q1, q3 = df['normalized_salary'].quantile([0.25, 0.75])\n",
    "low  = max(q1 - 1.5*(q3 - q1), 0)\n",
    "high = q3 + 1.5*(q3 - q1)\n",
    "df['normalized_salary'] = df['normalized_salary'].clip(low, high)\n",
    "\n",
    "to_drop_salary = [\n",
    "    'min_salary','med_salary','max_salary',\n",
    "    'min_salary_annual','med_salary_annual','max_salary_annual',\n",
    "    'pay_period'\n",
    "]\n",
    "df = df.drop(columns=to_drop_salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\n",
    "    'postings',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benefits = pd.read_sql_table('benefits', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benefits = df_benefits[df_benefits['job_id'].isin(df['job_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benefits['type'] = df_benefits['type'].str.strip().str.lower()\n",
    "df_benefits = (\n",
    "    df_benefits\n",
    "    .dropna(subset=['job_id','type'])\n",
    "    .drop_duplicates(subset=['job_id','type'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benefits = (\n",
    "    df_benefits\n",
    "    .groupby('job_id', as_index=False)\n",
    "    .agg(benefits_count=('type','size'))\n",
    ")\n",
    "df_benefits['has_benefits'] = (df_benefits['benefits_count'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benefits.to_sql(\n",
    "    'benefits',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_industries = pd.read_sql_table('job_industries', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_industries = df_job_industries[df_job_industries['job_id'].isin(df['job_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_industries = df_job_industries.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries = pd.read_sql_table('industries', schema='raw', con=engine)[['industry_id']]\n",
    "df_job_industries = df_job_industries[\n",
    "    df_job_industries['industry_id'].isin(df_industries['industry_id'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_industries.to_sql(\n",
    "    'job_industries',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_skills = pd.read_sql_table('job_skills', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_skills = df_job_skills[df_job_skills['job_id'].isin(df['job_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_skills['skill_abr'] = df_job_skills['skill_abr'].str.strip().str.upper()\n",
    "df_job_skills = df_job_skills.dropna(subset=['job_id', 'skill_abr'])\n",
    "df_job_skills = df_job_skills.drop_duplicates(subset=['job_id', 'skill_abr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_skills.to_sql(\n",
    "    'job_skills',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.read_sql_table('companies', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep     = ['company_id', 'name', 'company_size']\n",
    "columns_from_table = df_companies.columns.tolist()\n",
    "actual_columns_to_keep = [col for col in columns_to_keep if col in columns_from_table]\n",
    "df_companies = df_companies[actual_columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'name' in df_companies.columns:\n",
    "    df_companies['name'] = (\n",
    "        df_companies['name']\n",
    "        .fillna('Unknown')\n",
    "        .str.strip()\n",
    "        .str.title()\n",
    "    )\n",
    "    \n",
    "if 'company_size' in df_companies.columns:\n",
    "    df_companies['company_size'] = (\n",
    "        df_companies['company_size']\n",
    "        .fillna(0)\n",
    "        .astype('Int8')\n",
    "    )\n",
    "    \n",
    "if 'company_id' in df_companies.columns:\n",
    "    df_companies = df_companies.dropna(subset=['company_id'])\n",
    "    df_companies['company_id'] = df_companies['company_id'].astype(int)\n",
    "    df_companies = (\n",
    "        df_companies\n",
    "        .drop_duplicates(subset=['company_id'])\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_companies.to_sql(\n",
    "    'companies',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp_counts = pd.read_sql_table('employee_counts', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp_counts = df_emp_counts.drop(columns='time_recorded')\n",
    "df_emp_counts = df_emp_counts.drop_duplicates(subset='company_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emp_counts.to_sql(\n",
    "    'employee_counts',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries = pd.read_sql_table('industries', schema='raw', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries['industry_name'] = (\n",
    "    df_industries['industry_name']\n",
    "    .fillna('Unknown')\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries = (\n",
    "    df_industries\n",
    "    .drop_duplicates(subset=['industry_id'])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────── Cell 4: Categorización por patrones ──────────────\n",
    "import re\n",
    "\n",
    "patterns = [\n",
    "    (r'\\b(manufacturing|production|fabrication)\\b',               'Manufacturing'),\n",
    "    (r'\\b(tech|it|information|computer|software|internet|data)\\b', 'Technology & IT'),\n",
    "    (r'\\b(health|medical|pharma|bio|dental|clinic|veterinary)\\b',  'Healthcare & Life Sciences'),\n",
    "    (r'\\b(finance|bank|insurance|investment|accounting)\\b',        'Finance & Insurance'),\n",
    "    (r'\\b(retail|e-commerce|fashion|apparel|luxury)\\b',            'Retail & Consumer Goods'),\n",
    "    (r'\\b(education|e-learning|school|training|academic)\\b',       'Education'),\n",
    "    (r'\\b(government|public|law|justice|military)\\b',              'Government & Public Sector'),\n",
    "    (r'\\b(media|entertainment|arts|sports|hospitality|travel)\\b',  'Media, Entertainment & Hospitality'),\n",
    "    (r'\\b(energy|oil|gas|mining|utilities|power|solar|wind)\\b',     'Energy, Mining & Utilities'),\n",
    "    (r'\\b(construction|real estate|architecture|engineering)\\b',   'Construction & Real Estate'),\n",
    "    (r'\\b(transportation|logistics|supply chain|automotive|aerospace)\\b','Transportation & Logistics'),\n",
    "    (r'\\b(food|beverage|restaurants|catering)\\b',                  'Food & Beverage Services'),\n",
    "    (r'\\b(non-?profit|charity|community)\\b',                       'Non-Profit & Social Organizations'),\n",
    "    (r'\\b(agriculture|farming|forestry|horticulture)\\b',            'Agriculture & Forestry'),\n",
    "    (r'other',                                                    'Other'),\n",
    "]\n",
    "\n",
    "def categorize(name: str) -> str:\n",
    "    nl = name.lower()\n",
    "    for pat, cat in patterns:\n",
    "        if re.search(pat, nl):\n",
    "            return cat\n",
    "    return 'Other'\n",
    "\n",
    "df_industries['industry_category'] = df_industries['industry_name'].apply(categorize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_industries = df_industries.drop(columns=['industry_name'])\n",
    "\n",
    "df_industries.to_sql(\n",
    "    'industries',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skills = pd.read_sql_table('skills', schema='raw', con=engine)\n",
    "\n",
    "df_skills['skill_abr']  = df_skills['skill_abr'].str.strip().str.upper()\n",
    "df_skills['skill_name'] = df_skills['skill_name'].str.strip().str.title()\n",
    "\n",
    "df_skills = df_skills.drop_duplicates(subset=['skill_abr']).reset_index(drop=True)\n",
    "skill_map = dict(zip(df_skills['skill_abr'], df_skills['skill_name']))\n",
    "\n",
    "df_skills.to_sql(\n",
    "    'skills_lookup',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_js = pd.read_sql_table('job_skills', schema='cleaned', con=engine)\n",
    "\n",
    "df_job_skills_list = (\n",
    "    df_js\n",
    "    .groupby('job_id')['skill_abr']\n",
    "    .agg(','.join)                   \n",
    "    .reset_index()\n",
    "    .rename(columns={'skill_abr':'skills_list'})\n",
    ")\n",
    "df_job_skills_list['skills_list'] = (\n",
    "    df_job_skills_list['skills_list']\n",
    "    .str.split(',')\n",
    "    .apply(lambda codes: [skill_map.get(code, code) for code in codes])\n",
    "    .apply(lambda names: ','.join(names))\n",
    ")\n",
    "\n",
    "df_job_skills_list.to_sql(\n",
    "    'job_skills_list',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ji  = pd.read_sql_table('job_industries', schema='cleaned', con=engine)\n",
    "df_ind = pd.read_sql_table('industries',    schema='cleaned', con=engine)\n",
    "\n",
    "df_job_industry_cat = (\n",
    "    df_ji\n",
    "    .merge(df_ind[['industry_id','industry_category']], on='industry_id', how='left')\n",
    "    .drop_duplicates(subset='job_id', keep='first')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_job_industry_cat.to_sql(\n",
    "    'job_industries_category',\n",
    "    con=engine,\n",
    "    schema='cleaned',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df              = pd.read_sql_table('postings',               schema='cleaned',         con=engine)\n",
    "df_benefits     = pd.read_sql_table('benefits',              schema='cleaned',         con=engine)\n",
    "df_ind_cat      = pd.read_sql_table('job_industries_category', schema='cleaned',       con=engine)\n",
    "df_skills_list  = pd.read_sql_table('job_skills_list',       schema='cleaned',         con=engine)\n",
    "df_companies    = pd.read_sql_table('companies',             schema='cleaned',         con=engine)\n",
    "df_emp_counts   = pd.read_sql_table('employee_counts',       schema='cleaned',         con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.copy()\n",
    "\n",
    "df_merged = (\n",
    "    df_merged\n",
    "    .merge(\n",
    "        df_benefits[['job_id','has_benefits','benefits_count']],\n",
    "        on='job_id', how='left'\n",
    "    )\n",
    "    .fillna({'has_benefits':0, 'benefits_count':0})\n",
    ")\n",
    "\n",
    "df_merged = (\n",
    "    df_merged\n",
    "    .merge(\n",
    "        df_ind_cat[['job_id','industry_category']],\n",
    "        on='job_id', how='left'\n",
    "    )\n",
    "    .fillna({'industry_category':'Unknown'})\n",
    ")\n",
    "\n",
    "df_merged = (\n",
    "    df_merged\n",
    "    .merge(\n",
    "        df_skills_list[['job_id','skills_list']],\n",
    "        on='job_id', how='left'\n",
    "    )\n",
    "    .fillna({'skills_list':''})\n",
    ")\n",
    "\n",
    "df_merged = (\n",
    "    df_merged\n",
    "    .merge(\n",
    "        df_companies[['company_id','company_size']],\n",
    "        on='company_id', how='left'\n",
    "    )\n",
    "    .fillna({'company_size':0})\n",
    "    .astype({'company_size':int})\n",
    ")\n",
    "\n",
    "df_merged = (\n",
    "    df_merged\n",
    "    .merge(\n",
    "        df_emp_counts[['company_id','employee_count','follower_count']],\n",
    "        on='company_id', how='left'\n",
    "    )\n",
    "    .fillna({'employee_count':0,'follower_count':0})\n",
    "    .astype({'employee_count':int,'follower_count':int})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\n",
    "    'company_name',\n",
    "    'formatted_work_type',\n",
    "    'application_type',\n",
    "    'formatted_experience_level',\n",
    "    'state_only',\n",
    "    'original_listed_month',\n",
    "    'industry_category',\n",
    "    'skills_list'\n",
    "]\n",
    "\n",
    "for col in text_cols:\n",
    "    df_merged[col] = df_merged[col].fillna('').astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.to_sql(\n",
    "    'merge',\n",
    "    con=engine,\n",
    "    schema='dimensional_model',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
