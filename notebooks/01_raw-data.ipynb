{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROJECT - NOTEBOOK #1: Raw Data**\n",
    "\n",
    "This notebook sets up our data pipeline by configuring the environment, importing essential libraries and create a SQLAlchemy engine, then loading raw data from the CSV file into a Pandas DataFrame, transferring this data into a MySQL database, and verifying the transfer with a simple query.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setting Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\U\\FIFTH SEMESTER\\ETL\\project_etl\\notebooks\n",
      "d:\\U\\FIFTH SEMESTER\\ETL\\project_etl\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())\n",
    "\n",
    "try:\n",
    "    os.chdir(\"../../project_etl\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\"\"\n",
    "        FileNotFoundError - The directory may not exist or you might not be in the specified path.\n",
    "        If this has already worked, do not run this block again, as the current directory is already set to workshop-001.\n",
    "        \"\"\")\n",
    "    \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing modules and libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arshkon/linkedin-job-postings\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataset_dir = path\n",
    "csv_file = os.path.join(dataset_dir, \"postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functions.db_connection.connection import creating_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ingest Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully!\n",
      "First 5 rows of the dataset:\n",
      "     job_id            company_name  \\\n",
      "0    921716   Corcoran Sawyer Smith   \n",
      "1   1829192                     NaN   \n",
      "2  10998357  The National Exemplar    \n",
      "3  23221523  Abrams Fensterman, LLP   \n",
      "4  35982263                     NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0                              Marketing Coordinator   \n",
      "1                  Mental Health Therapist/Counselor   \n",
      "2                        Assitant Restaurant Manager   \n",
      "3  Senior Elder Law / Trusts and Estates Associat...   \n",
      "4                                 Service Technician   \n",
      "\n",
      "                                         description  max_salary pay_period  \\\n",
      "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
      "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
      "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
      "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
      "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
      "\n",
      "            location  company_id  views  med_salary  ...  \\\n",
      "0      Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
      "1   Fort Collins, CO         NaN    1.0         NaN  ...   \n",
      "2     Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
      "3  New Hyde Park, NY    766262.0   16.0         NaN  ...   \n",
      "4     Burlington, IA         NaN    3.0         NaN  ...   \n",
      "\n",
      "                                         skills_desc   listed_time  \\\n",
      "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
      "1                                                NaN  1.712858e+12   \n",
      "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
      "3  This position requires a baseline understandin...  1.712896e+12   \n",
      "4                                                NaN  1.713452e+12   \n",
      "\n",
      "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
      "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "3             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "4             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "\n",
      "  normalized_salary  zip_code     fips  \n",
      "0           38480.0    8540.0  34021.0  \n",
      "1           83200.0   80521.0   8069.0  \n",
      "2           55000.0   45202.0  39061.0  \n",
      "3          157500.0   11040.0  36059.0  \n",
      "4           70000.0   52601.0  19057.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(\"DataFrame loaded successfully!\")\n",
    "    print(\"First 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Error: '{csv_file}' not found in {dataset_dir}\")\n",
    "    print(\"Available files:\", os.listdir(dataset_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project_etl)",
   "language": "python",
   "name": "project_etl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
