{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROJECT - NOTEBOOK #1: Raw Data**\n",
    "\n",
    "> ðŸš§ Run this notebook only once to migrate the data to your DB (It will take a few minutes)\n",
    "\n",
    "This notebook sets up our data pipeline by configuring the environment, importing essential libraries and create a SQLAlchemy engine, then loading raw data from the CSV file into a Pandas DataFrame, transferring this data into a MySQL database, and verifying the transfer with a simple query.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setting Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\U\\FIFTH SEMESTER\\ETL\\project_etl\\notebooks\n",
      "d:\\U\\FIFTH SEMESTER\\ETL\\project_etl\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())\n",
    "\n",
    "try:\n",
    "    os.chdir(\"../../project_etl\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\"\"\n",
    "        FileNotFoundError - The directory may not exist or you might not be in the specified path.\n",
    "        If this has already worked, do not run this block again, as the current directory is already set to project_etl.\n",
    "        \"\"\")\n",
    "    \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing modules and libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy import text\n",
    "from src.database.db_connection import create_gcp_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ingest Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\project-etl-viN8x_kB-py3.13\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded jobs from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\postings.csv with 123849 rows\n",
      "INFO:__main__:Loaded benefits from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\jobs\\benefits.csv with 67943 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame 'jobs' loaded successfully!\n",
      "First 5 rows of 'jobs':\n",
      "     job_id            company_name  \\\n",
      "0    921716   Corcoran Sawyer Smith   \n",
      "1   1829192                     NaN   \n",
      "2  10998357  The National Exemplar    \n",
      "3  23221523  Abrams Fensterman, LLP   \n",
      "4  35982263                     NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0                              Marketing Coordinator   \n",
      "1                  Mental Health Therapist/Counselor   \n",
      "2                        Assitant Restaurant Manager   \n",
      "3  Senior Elder Law / Trusts and Estates Associat...   \n",
      "4                                 Service Technician   \n",
      "\n",
      "                                         description  max_salary pay_period  \\\n",
      "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
      "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
      "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
      "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
      "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
      "\n",
      "            location  company_id  views  med_salary  ...  \\\n",
      "0      Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
      "1   Fort Collins, CO         NaN    1.0         NaN  ...   \n",
      "2     Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
      "3  New Hyde Park, NY    766262.0   16.0         NaN  ...   \n",
      "4     Burlington, IA         NaN    3.0         NaN  ...   \n",
      "\n",
      "                                         skills_desc   listed_time  \\\n",
      "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
      "1                                                NaN  1.712858e+12   \n",
      "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
      "3  This position requires a baseline understandin...  1.712896e+12   \n",
      "4                                                NaN  1.713452e+12   \n",
      "\n",
      "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
      "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "3             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "4             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "\n",
      "  normalized_salary  zip_code     fips  \n",
      "0           38480.0    8540.0  34021.0  \n",
      "1           83200.0   80521.0   8069.0  \n",
      "2           55000.0   45202.0  39061.0  \n",
      "3          157500.0   11040.0  36059.0  \n",
      "4           70000.0   52601.0  19057.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "DataFrame 'benefits' loaded successfully!\n",
      "First 5 rows of 'benefits':\n",
      "       job_id  inferred                     type\n",
      "0  3887473071         0        Medical insurance\n",
      "1  3887473071         0         Vision insurance\n",
      "2  3887473071         0         Dental insurance\n",
      "3  3887473071         0                   401(k)\n",
      "4  3887473071         0  Student loan assistance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded companies from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\companies\\companies.csv with 24473 rows\n",
      "INFO:__main__:Loaded employee_counts from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\companies\\employee_counts.csv with 35787 rows\n",
      "INFO:__main__:Loaded industries from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\mappings\\industries.csv with 422 rows\n",
      "INFO:__main__:Loaded skills_industries from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\mappings\\skills.csv with 35 rows\n",
      "INFO:__main__:Loaded salaries from C:\\Users\\sebas\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\\jobs\\salaries.csv with 40785 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame 'companies' loaded successfully!\n",
      "First 5 rows of 'companies':\n",
      "   company_id                        name  \\\n",
      "0        1009                         IBM   \n",
      "1        1016               GE HealthCare   \n",
      "2        1025  Hewlett Packard Enterprise   \n",
      "3        1028                      Oracle   \n",
      "4        1033                   Accenture   \n",
      "\n",
      "                                         description  company_size  state  \\\n",
      "0  At IBM, we do more than work. We create. We cr...           7.0     NY   \n",
      "1  Every day millions of people feel the impact o...           7.0      0   \n",
      "2  Official LinkedIn of Hewlett Packard Enterpris...           7.0  Texas   \n",
      "3  Weâ€™re a cloud technology company that provides...           7.0  Texas   \n",
      "4  Accenture is a leading global professional ser...           7.0      0   \n",
      "\n",
      "  country              city zip_code                                address  \\\n",
      "0      US  Armonk, New York    10504  International Business Machines Corp.   \n",
      "1      US           Chicago        0                                      -   \n",
      "2      US           Houston    77389            1701 E Mossy Oaks Rd Spring   \n",
      "3      US            Austin    78741                        2300 Oracle Way   \n",
      "4      IE          Dublin 2        0                    Grand Canal Harbour   \n",
      "\n",
      "                                                 url  \n",
      "0               https://www.linkedin.com/company/ibm  \n",
      "1      https://www.linkedin.com/company/gehealthcare  \n",
      "2  https://www.linkedin.com/company/hewlett-packa...  \n",
      "3            https://www.linkedin.com/company/oracle  \n",
      "4         https://www.linkedin.com/company/accenture  \n",
      "\n",
      "DataFrame 'employee_counts' loaded successfully!\n",
      "First 5 rows of 'employee_counts':\n",
      "   company_id  employee_count  follower_count  time_recorded\n",
      "0      391906             186           32508     1712346173\n",
      "1    22292832             311            4471     1712346173\n",
      "2       20300            1053            6554     1712346173\n",
      "3     3570660             383           35241     1712346173\n",
      "4      878353              52           26397     1712346173\n",
      "\n",
      "DataFrame 'industries' loaded successfully!\n",
      "First 5 rows of 'industries':\n",
      "   industry_id                         industry_name\n",
      "0            1       Defense and Space Manufacturing\n",
      "1            3       Computer Hardware Manufacturing\n",
      "2            4                  Software Development\n",
      "3            5          Computer Networking Products\n",
      "4            6  Technology, Information and Internet\n",
      "\n",
      "DataFrame 'skills_industries' loaded successfully!\n",
      "First 5 rows of 'skills_industries':\n",
      "  skill_abr          skill_name\n",
      "0       ART        Art/Creative\n",
      "1      DSGN              Design\n",
      "2      ADVR         Advertising\n",
      "3      PRDM  Product Management\n",
      "4      DIST        Distribution\n",
      "\n",
      "DataFrame 'salaries' loaded successfully!\n",
      "First 5 rows of 'salaries':\n",
      "   salary_id      job_id  max_salary  med_salary  min_salary pay_period  \\\n",
      "0          1  3884428798         NaN        20.0         NaN     HOURLY   \n",
      "1          2  3887470552        25.0         NaN        23.0     HOURLY   \n",
      "2          3  3884431523    120000.0         NaN    100000.0     YEARLY   \n",
      "3          4  3884911725    200000.0         NaN     10000.0     YEARLY   \n",
      "4          5  3887473220        35.0         NaN        33.0     HOURLY   \n",
      "\n",
      "  currency compensation_type  \n",
      "0      USD       BASE_SALARY  \n",
      "1      USD       BASE_SALARY  \n",
      "2      USD       BASE_SALARY  \n",
      "3      USD       BASE_SALARY  \n",
      "4      USD       BASE_SALARY  \n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"arshkon/linkedin-job-postings\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataset_dir = path\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "csv_files = {\n",
    "    'jobs': os.path.join(dataset_dir, \"postings.csv\"),\n",
    "    'benefits': os.path.join(dataset_dir, \"jobs\", \"benefits.csv\"),\n",
    "    'companies': os.path.join(dataset_dir, \"companies\", \"companies.csv\"),\n",
    "    'employee_counts': os.path.join(dataset_dir, \"companies\", \"employee_counts.csv\"), \n",
    "    \n",
    "    #Added CSV files besides the main ones in order to create the fact table\n",
    "    'industries': os.path.join(dataset_dir, \"mappings\", \"industries.csv\"), \n",
    "    'skills_industries': os.path.join(dataset_dir, \"mappings\", \"skills.csv\"),\n",
    "    'salaries': os.path.join(dataset_dir, \"jobs\", \"salaries.csv\"),\n",
    "}\n",
    "\n",
    "for name, file_path in csv_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        dfs[name] = pd.read_csv(file_path)\n",
    "        logger.info(f\"Loaded {name} from {file_path} with {len(dfs[name])} rows\")\n",
    "        print(f\"\\nDataFrame '{name}' loaded successfully!\")\n",
    "        print(f\"First 5 rows of '{name}':\")\n",
    "        print(dfs[name].head())\n",
    "    else:\n",
    "        logger.error(f\"Error: '{file_path}' not found\")\n",
    "        print(f\"Error: '{file_path}' not found in {dataset_dir}\")\n",
    "        print(\"Available files:\", os.listdir(dataset_dir if 'jobs' not in file_path else os.path.join(dataset_dir, \"jobs\")))\n",
    "\n",
    "#Access to a specific Dataframe\n",
    "if 'postings' in dfs:\n",
    "    print(\"\\nColumns in postings DataFrame:\")\n",
    "    print(dfs['postings'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transfer data to DB in GCP Cloud SQL (raw schema)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.database.db_connection:Successfully created GCP database engine\n",
      "INFO:__main__:Successfully connected to GCP database\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    engine = create_gcp_engine()\n",
    "    logger.info(\"Successfully connected to GCP database\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to connect to GCP database: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:PostgreSQL Version: PostgreSQL 16.8 on x86_64-pc-linux-gnu, compiled by Debian clang version 12.0.1, 64-bit\n",
      "INFO:__main__:Table 'jobs' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.jobs has 123849 rows\n",
      "INFO:__main__:Table 'benefits' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.benefits has 67943 rows\n",
      "INFO:__main__:Table 'companies' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.companies has 24473 rows\n",
      "INFO:__main__:Table 'employee_counts' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.employee_counts has 35787 rows\n",
      "INFO:__main__:Table 'industries' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.industries has 422 rows\n",
      "INFO:__main__:Table 'skills_industries' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.skills_industries has 35 rows\n",
      "INFO:__main__:Table 'salaries' successfully loaded into raw schema!\n",
      "INFO:__main__:Validation: raw.salaries has 40785 rows\n",
      "INFO:__main__:\n",
      "Tables in raw schema of project-etl database:\n",
      "INFO:__main__:jobs\n",
      "INFO:__main__:benefits\n",
      "INFO:__main__:companies\n",
      "INFO:__main__:employee_counts\n",
      "INFO:__main__:industries\n",
      "INFO:__main__:skills_industries\n",
      "INFO:__main__:salaries\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text('SELECT version();'))\n",
    "        logger.info(f'PostgreSQL Version: {result.fetchone()[0]}')\n",
    "except Exception as e:\n",
    "    logger.error(f'Connection verification failed: {e}')\n",
    "    raise\n",
    "\n",
    "#Load each DataFrame into the 'raw' schema\n",
    "for name, df in dfs.items():\n",
    "    try:\n",
    "        with engine.begin() as connection:\n",
    "            df.to_sql(name.lower(), con=connection, schema='raw', if_exists='replace', index=False)\n",
    "            logger.info(f\"Table '{name}' successfully loaded into raw schema!\")\n",
    "            \n",
    "            # Validate\n",
    "            result = connection.execute(text(f\"SELECT COUNT(*) FROM raw.{name}\"))\n",
    "            row_count = result.fetchone()[0]\n",
    "            logger.info(f\"Validation: raw.{name} has {row_count} rows\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading '{name}' into raw schema: {e}\")\n",
    "        raise\n",
    "\n",
    "#Verify all tables in the raw schema\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'raw';\"))\n",
    "        logger.info('\\nTables in raw schema of project-etl database:')\n",
    "        for row in result:\n",
    "            logger.info(row[0])\n",
    "except Exception as e:\n",
    "    logger.error(f'Verification failed: {e}')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the engine\n",
    "engine.dispose()\n",
    "logger.info(\"Closed connection to GCP database.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project_etl)",
   "language": "python",
   "name": "project_etl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
