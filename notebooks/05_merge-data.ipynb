{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROJECT - NOTEBOOK #4: Merge LinkedIn and USAJOBS Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setting Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/linkedin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table merge not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_linkedin = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_table\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmerge\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdimensional_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/university/etl/project_linux_repo/LinkedIn-Jobs-Posting/airflow_env/lib/python3.11/site-packages/pandas/io/sql.py:282\u001b[39m, in \u001b[36mread_sql_table\u001b[39m\u001b[34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[39m\n\u001b[32m    280\u001b[39m pandas_sql = pandasSQL_builder(con, schema=schema)\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pandas_sql.has_table(table_name):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# error: Item \"SQLiteDatabase\" of \"Union[SQLDatabase, SQLiteDatabase]\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;66;03m# has no attribute \"read_table\"\u001b[39;00m\n\u001b[32m    286\u001b[39m table = pandas_sql.read_table(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m    287\u001b[39m     table_name,\n\u001b[32m    288\u001b[39m     index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    292\u001b[39m     chunksize=chunksize,\n\u001b[32m    293\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Table merge not found"
     ]
    }
   ],
   "source": [
    "df_linkedin = pd.read_sql_table('merge', schema='dimensional_model', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data_api/usajobs_data.csv')\\\n",
    "  .to_sql('usajobs_data', con=engine, schema='dimensional_model',\n",
    "          if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkedin = pd.read_sql_table('merge',        schema='dimensional_model', con=engine)\n",
    "df_usajobs  = pd.read_sql_table('usajobs_data', schema='dimensional_model', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_URL = 'https://gist.githubusercontent.com/mshafrir/2646763/raw/states_titlecase.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [\n",
    "    'job_id', 'company_id', 'company_name', 'company_size',\n",
    "    'employee_count', 'follower_count', 'views', 'applies',\n",
    "    'formatted_work_type', 'remote_allowed', 'application_type',\n",
    "    'formatted_experience_level', 'normalized_salary', 'len_description',\n",
    "    'state_only', 'original_listed_month', 'original_listed_year',\n",
    "    'has_benefits', 'benefits_count', 'industry_category', 'skills_list'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = {\n",
    "    **{c: 0      for c in [\n",
    "        'company_id','company_size','employee_count','follower_count',\n",
    "        'views','applies','len_description','has_benefits','benefits_count'\n",
    "    ]},\n",
    "    **{c: 'unknown' for c in [\n",
    "        'company_name','formatted_work_type','application_type','formatted_experience_level'\n",
    "    ]},\n",
    "    'skills_list': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_patterns = {\n",
    "    r'\\b(manufacturing|production|fabrication)\\b':             'Manufacturing',\n",
    "    r'\\b(tech|it|information|computer|software|internet|data)\\b': 'Technology & IT',\n",
    "    r'\\b(health|medical|pharma|bio|dental|clinic|veterinary)\\b':'Healthcare & Life Sciences',\n",
    "    r'\\b(finance|bank|insurance|investment|accounting)\\b':      'Finance & Insurance',\n",
    "    r'\\b(retail|e-commerce|fashion|apparel|luxury)\\b':          'Retail & Consumer Goods',\n",
    "    r'\\b(education|e-learning|school|training|academic)\\b':     'Education',\n",
    "    r'\\b(government|public|law|justice|military)\\b':            'Government & Public Sector',\n",
    "    r'\\b(media|entertainment|arts|sports|hospitality|travel)\\b':'Media, Entertainment & Hospitality',\n",
    "    r'\\b(energy|oil|gas|mining|utilities|power|solar|wind)\\b':   'Energy, Mining & Utilities',\n",
    "    r'\\b(construction|real estate|architecture|engineering)\\b':'Construction & Real Estate',\n",
    "    r'\\b(transportation|logistics|supply chain|automotive|aerospace)\\b':'Transportation & Logistics',\n",
    "    r'\\b(food|beverage|restaurants|catering)\\b':               'Food & Beverage Services',\n",
    "    r'\\b(non-?profit|charity|community)\\b':                    'Non-Profit & Social Organizations',\n",
    "    r'\\b(agriculture|farming|forestry|horticulture)\\b':         'Agriculture & Forestry',\n",
    "    r'other':                                                     'OTHER'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_industry(cat: str) -> str:\n",
    "    \"\"\"Mapea una categorÃ­a a nuestros grupos definidos.\"\"\"\n",
    "    if pd.isna(cat) or cat == 'other':\n",
    "        return 'other'\n",
    "    cat_lower = cat.lower()\n",
    "    for pat, label in category_patterns.items():\n",
    "        if re.search(pat, cat_lower):\n",
    "            return label\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "def extract_state(loc: str, abbr_map: dict, name_map: dict) -> str:\n",
    "    \"\"\"Extrae la abreviatura del estado de una cadena location.\"\"\"\n",
    "    if pd.isna(loc) or not isinstance(loc, str):\n",
    "        return 'other'\n",
    "    for frag in reversed(loc.split(',')):\n",
    "        frag = frag.strip()\n",
    "        if frag.upper() in abbr_map:\n",
    "            return frag.upper()\n",
    "        if frag.lower() in name_map:\n",
    "            return name_map[frag.lower()]\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = json.load(urlopen(STATE_URL))\n",
    "abbr_map = {i['abbreviation']: i['abbreviation'] for i in state_list}\n",
    "name_map = {i['name'].lower(): i['abbreviation'] for i in state_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs.rename(columns={'State': 'state_only'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df_linkedin, df_usajobs):\n",
    "    df['state_only'] = df['state_only'].apply(extract_state, args=(abbr_map, name_map))\n",
    "\n",
    "df_usajobs.rename(columns={\n",
    "    'PositionID': 'job_id',\n",
    "    'NormalisedSalary': 'normalized_salary',\n",
    "    'TeleworkEligible':  'remote_allowed',\n",
    "    'JobCategory':       'industry_category',\n",
    "    'PublicationDate':   'original_listed_time'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usajobs['original_listed_month'] = (\n",
    "    pd.to_datetime(df_usajobs.pop('original_listed_time'), errors='coerce')\n",
    "      .dt.month_name().fillna('other')\n",
    ")\n",
    "df_usajobs['original_listed_year'] = (\n",
    "    pd.to_datetime(df_usajobs['original_listed_month'], format='%B', errors='coerce')\n",
    "      .dt.year.fillna(0).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in df_usajobs after state processing:\n",
      "['job_id', 'PositionTitle', 'PositionURI', 'Location', 'City', 'state_only', 'Country', 'Latitude', 'Longitude', 'Organization', 'Department', 'MinSalary', 'MaxSalary', 'SalaryInterval', 'industry_category', 'JobGrade', 'Schedule', 'OfferingType', 'StartDate', 'EndDate', 'CloseDate', 'remote_allowed', 'SecurityClearance', 'PromotionPotential', 'TravelCode', 'HiringPath', 'TotalOpenings', 'normalized_salary', 'original_listed_month', 'original_listed_year']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumns in df_usajobs after state processing:\")\n",
    "print(df_usajobs.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df_linkedin, df_usajobs):\n",
    "    df['normalized_salary'] = (\n",
    "        pd.to_numeric(df['normalized_salary'], errors='coerce')\n",
    "          .fillna(0)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'industry_category' in df_usajobs:\n",
    "    df_usajobs['industry_category'] = (\n",
    "        df_usajobs['industry_category']\n",
    "          .fillna('other')\n",
    "          .apply(map_industry)\n",
    "          .str.lower()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkedin = df_linkedin.reindex(columns=final_columns).fillna(defaults)\n",
    "df_linkedin['job_id'] = df_linkedin['job_id'].astype(str)\n",
    "\n",
    "aligned = {\n",
    "    'job_id':              df_usajobs['job_id'].astype(str),\n",
    "    'remote_allowed':      df_usajobs['remote_allowed'],\n",
    "    'normalized_salary':   df_usajobs['normalized_salary'],\n",
    "    'state_only':          df_usajobs['state_only'],\n",
    "    'original_listed_month': df_usajobs['original_listed_month'],\n",
    "    'original_listed_year':  df_usajobs['original_listed_year'],\n",
    "    'industry_category':   df_usajobs['industry_category'],\n",
    "}\n",
    "df_usajobs_aligned = pd.DataFrame(aligned)\n",
    "for col in final_columns:\n",
    "    if col not in df_usajobs_aligned:\n",
    "        df_usajobs_aligned[col] = defaults[col]\n",
    "\n",
    "df_usajobs_aligned = df_usajobs_aligned.reindex(columns=final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\n",
    "    'company_name','formatted_work_type','application_type',\n",
    "    'formatted_experience_level','state_only','original_listed_month',\n",
    "    'industry_category','skills_list'\n",
    "]\n",
    "for df in (df_linkedin, df_usajobs):\n",
    "    for col in text_cols:\n",
    "        if col in df:\n",
    "            df[col] = df[col].fillna('').astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df_linkedin, df_usajobs_aligned], ignore_index=True)\n",
    "result = result.drop_duplicates(subset=['job_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to ../data_merged/merge_with_api.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"../data_merged/merge_with_api.csv\"\n",
    "result.to_csv(output_file, index=False)\n",
    "print(f\"Merged data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_sql(\n",
    "    name='merge_with_api',\n",
    "    con=engine,\n",
    "    schema='dimensional_model',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
